{"cells":[{"cell_type":"markdown","metadata":{"id":"9MiHp58KI7c_"},"source":["# Problem 3, Parts F-H: Stochastic Gradient Descent with a Larger Dataset"]},{"cell_type":"markdown","metadata":{"id":"xBMavqB9I7dD"},"source":["Use this notebook to write your code for problem 3 parts F-H by filling in the sections marked `# TODO` and running all cells."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zD8uOTAbI7dE"},"outputs":[],"source":["# Setup.\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"KmeowyuSI7dF"},"source":["## Problem 3F: Perform SGD with the new dataset"]},{"cell_type":"markdown","metadata":{"id":"b_Yr_uEXI7dG"},"source":["For the functions below, you may re-use your code from parts 3C-E. Note that you can now modify your SGD function to return the final weight vector instead of the weights after every epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"lOqNtnhXI7dG"},"outputs":[],"source":["def loss(X, Y, w):\n","    '''\n","    Calculate the squared loss function.\n","    \n","    Inputs:\n","        X: A (N, D) shaped numpy array containing the data points.\n","        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n","        w: A (D, ) shaped numpy array containing the weight vector.\n","    \n","    Outputs:\n","        The loss evaluated with respect to X, Y, and w.\n","    '''\n","    total = 0\n","    for i in range(len(X)):\n","      total += (Y[i]-np.matmul(np.transpose(w),X[i]))**2\n","    return total\n","\n","def gradient(x, y, w):\n","    '''\n","    Calculate the gradient of the loss function with respect to\n","    a single point (x, y), and using weight vector w.\n","    \n","    Inputs:\n","        x: A (D, ) shaped numpy array containing a single data point.\n","        y: The float label for the data point.\n","        w: A (D, ) shaped numpy array containing the weight vector.\n","        \n","    Output:\n","        The gradient of the loss with respect to x, y, and w. \n","    '''\n","    return -2*np.array(x)*(y-np.matmul(np.transpose(w),x))\n","\n","def SGD(X, Y, w_start, eta, N_epochs):\n","    '''\n","    Perform SGD using dataset (X, Y), initial weight vector w_start,\n","    learning rate eta, and N_epochs epochs.\n","    \n","    Inputs:\n","        X: A (N, D) shaped numpy array containing the data points.\n","        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n","        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n","        eta: The step size.\n","        N_epochs: The number of epochs (iterations) to run SGD.\n","        \n","    Outputs:\n","        w: A (D, ) shaped array containing the final weight vector.\n","        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n","    '''\n","    losses = []\n","    w = np.array(w_start)\n","    for i in range(N_epochs):\n","      shuffle = np.random.permutation(len(X))\n","      X = X[shuffle]\n","      Y = Y[shuffle]\n","      for point in range(len(X)):\n","        w -= eta*gradient(X[point],Y[point],w)\n","      losses.append(loss(X, Y, w))\n","    return (w,losses)"]},{"cell_type":"markdown","metadata":{"id":"URle0yiaI7dI"},"source":["Next, we need to load the dataset. In doing so, the following function may be helpful:"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"HawZHA9-I7dJ"},"outputs":[],"source":["def load_data(filename):\n","    \"\"\"\n","    Function loads data stored in the file filename and returns it as a numpy ndarray.\n","    \n","    Inputs:\n","        filename: GeneratorExitiven as a string.\n","    \n","    Outputs:\n","        Data contained in the file, returned as a numpy ndarray\n","    \"\"\"\n","    return np.loadtxt(filename, skiprows=1, delimiter=',')"]},{"cell_type":"markdown","metadata":{"id":"miOL66ooI7dJ"},"source":["Now, load the dataset in `sgd_data.csv` and run SGD using the given parameters; print out the final weights."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"w8zujpzQI7dK","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1644271849914,"user_tz":480,"elapsed":11101,"user":{"displayName":"Kyle McGraw","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNZBB-SaBpeASp5tGkoYBpkdS97ilYm43l12cC=s64","userId":"08094409842851891056"}},"outputId":"397584fa-fdbd-4550-8428-440a959cc8cd"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-664febc0da0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mN_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mw_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-bced093ed25f>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(X, Y, w_start, eta, N_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-bced093ed25f>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(x, y, w)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     '''\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#==============================================\n","# TODO:\n","# (1) load the dataset\n","# (2) run SGD using the given parameters\n","# (3) print out the final weights.\n","#==============================================\n","\n","# The following should help you get started:\n","data = load_data('https://raw.githubusercontent.com/charlesincharge/Caltech-CS155-2022/main/sets/set1/data/sgd_data.csv')\n","X = np.insert(data,0,1,axis=1)[:,:5]\n","Y = np.insert(data,0,1,axis=1)[:,5:]\n","w_start = [0.001,0.001,0.001,0.001,0.001]\n","eta = np.exp(-15)\n","N_epochs = 800\n","(w_end, losses) = SGD(X, Y, w_start, eta, N_epochs)\n","print(w_end)"]},{"cell_type":"markdown","metadata":{"id":"hrQbch5ZI7dL"},"source":["## Problem 3G: Convergence of SGD"]},{"cell_type":"markdown","metadata":{"id":"wifm5ZIMI7dL"},"source":["This problem examines the convergence of SGD for different learning rates. Please implement your code in the cell below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gV4SipwAI7dL"},"outputs":[],"source":["#==============================================\n","# TODO: create a plot showing the convergence\n","# of SGD for the different learning rates.\n","#==============================================\n","eta_vals = [np.exp(-10), np.exp(-11), np.exp(-12), np.exp(-13), np.exp(-14), np.exp(-15)]\n","training_error = []\n","for eta in eta_vals:\n","  (weights, losses) = SGD(X, Y, w_start, eta, N_epochs)\n","  training_error.append(losses)\n","\n","plt.figure()\n","\n","plt.plot(range(N_epochs), training_error[0], marker = 'o', linewidth = 0)\n","plt.plot(range(N_epochs), training_error[1], marker = 'o', linewidth = 0)\n","plt.plot(range(N_epochs), training_error[2], marker = 'o', linewidth = 0)\n","plt.plot(range(N_epochs), training_error[3], marker = 'o', linewidth = 0)\n","plt.plot(range(N_epochs), training_error[4], marker = 'o', linewidth = 0)\n","plt.plot(range(N_epochs), training_error[5], marker = 'o', linewidth = 0)\n","\n","plt.legend(['e^-10 eta', 'e^-11 eta', 'e^-12 eta', 'e^-13 eta', 'e^-14 eta', 'e^-15 eta'], loc = 'best')\n","plt.xlabel('Number of Epochs')\n","plt.ylabel('Training Error')\n","plt.title('SGD Convergence by eta')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_vRECK4XI7dM"},"source":["## Problem 3H"]},{"cell_type":"markdown","metadata":{"id":"wCovlxnHI7dM"},"source":["Provide your code for computing the least-squares analytical solution below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PW5MWI-2I7dM"},"outputs":[],"source":["#==============================================\n","# TODO: implement the least-squares\n","# analytical solution.\n","#==============================================\n","w = np.matmul(np.linalg.inv(np.matmul(np.transpose(X),X)),np.matmul(np.transpose(X),Y))\n","print(w)"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [python3point5]","language":"python","name":"Python [python3point5]"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"mcgraw_kyle_3_notebook_part2.ipynb","provenance":[{"file_id":"https://github.com/charlesincharge/Caltech-CS155-2022/blob/main/sets/set1/3_notebook_part2.ipynb","timestamp":1641623751608}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}